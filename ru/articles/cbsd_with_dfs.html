<!--# include file="/ru/_start.html" -->
<h1><span>Использование <strong>CBSD</strong> совместно с DFS (Distributed File System)</span></h1>
<div class="block">

<h2><a name="dfs_generic">Общая информация</a></h2>

<p>Одной из отличительных особенностей <strong>CBSD</strong> от остальных современных оберток по управлению jail и bhyve на платформе FreeBSD является отсутствие жесткой привязки к файловой системе ZFS,
что влечет определенный оверхед с точки зрения кода, когда вы используете только ZFS, но делает <strong>CBSD</strong> более универсальным инструментом, который вы можете использовать в более широких ситуациях.</p>
<p>Одна из таких ситуаций - использование различных embedded платформ с очень небольшим количеством ресурсов где файловая система ZFS является избыточной и прожорливой, 
что делает ее малоэффективной на различных Raspberry PI и аналогичных решений. С противоположной стороны минимализма находятся большие и масштабные гиперконвергентные инсталляции с применением NAS/SAN 
и распределенных систем хранения данных, с использованием внешних хранилищ, подключаемых по протоколу NFS, iSCSI или таких файловых систем, как ClusterFS и Ceph.</p>

<p>Здесь будут освещены вопросы использования <strong>CBSD</strong> в подобных инсталляциях и описаны Howto-style записи по применению.</p>

<p>Общее требование при использовании <strong>CBSD</strong> на DFS, характерное для любых реализаций, это выключение <em>zfsfeat</em> и <em>hammerfeat</em> опции в 'cbsd initenv-tui' и необходимость выносить на общее хранилище следующих каталогов:</p>

<ul>
	<li>~cbsd/jails-data: каталог с данными контейнера или виртуальной машины</li>
	<li>~cbsd/jails-system: системный каталог с дополнительной системной информацией, относящейся к контейнеру или виртуальной машине</li>
	<li>~cbsd/jails-rcconf: каталог используется, когда окружение переходит в режим unregister</li>
	<li>~cbsd/jails-fstab: каталог используется, когда окружение переходит в режим unregister</li>
</ul>

<p>Если рабочий каталог (<strong>workdir</strong>) проинициализирован в <em>/usr/jails</em> это, соответственно, каталоги:</p>

<pre class="cli">
/usr/jails/jails-data
/usr/jails/jails-system
/usr/jails/jails-rcconf
/usr/jails/jails-fstab
</pre>

<p>Вы можете перенести на DFS указанные локации и смонтируете в одной точке все окружения, однако авторы рекомендуют разделять ресурсы на индивидуальные окружения.
Например, для контейнера jail1, экспортировать и монтировать непосредственно данные jail1, отдельные от других:</p>

<pre class="cli">
/usr/jails/jails-data/jail1-data
/usr/jails/jails-system/jail1
/usr/jails/jails-fstab/jail1
</pre>

<p>Это позволит вам оптимизировать работу файловых систем между окружениями и снизить потенциальное влияние деятельности одного окружения на другое - например, если окружение jail1
очень аггресивно использует лок на файловой системе, это будет влиять и на jail2 в случае, когда вы монтируете /usr/jails/jails-data, тогда как различные сессии и mount для
/usr/jails/jails-data/jail1-data и /usr/jails/jails-data/jail2-data будут независимы. Кроме этого, в этом случае вы можете использовать разные источники монтирования - ресурсы
jail1 могут находится на одном DFS сервере, а jail2 - на другом. Для этого, в <strong>CBSD</strong> присутствует механизм хуков для монтирования и размонтирования, о чем написано ниже.</p>

<p>Остальные каталоги, такие как bases вы также можете поместить на общее хранилище чтобы сэкономить место.
Однако, гораздо более эффективно базовые файлы контейнера хранить локально, что с параметром <strong>baserw=0</strong> по отношению к контейнерам гарантирует работу базовых утилит и библиотек
со скоростью локального диска и отсутствием возможных сетевых проблем.</p>

<p>Общие хранилища дают легкий способ миграции окружений с нулевым копированием. Так, вы можете перевести контейнера в состояние <strong>unregister</strong> на одной ноде:</p>

<p><strong>node1</strong>:</p>
<pre class="brush:bash;ruler:rule;">
% cbsd junregister jname='*'
</pre>

<p>И зарегистрировав, без какого-либо копирования начать использовать на другой:</p>

<p><strong>node2</strong>:</p>
<pre class="brush:bash;ruler:rule;">
% cbsd jregister jname='*'
</pre>

<p>Known issues.</p>

<p>На некоторых DFS, таких как NFSv3 и GlusterFS, требуется дополнительная настройка в pkg.conf для корректной работы локинга:</p>

<pre class="brush:bash;ruler:rule;">
 % echo "NFS_WITH_PROPER_LOCKING = true;" >> /usr/local/etc/pkg.conf
</pre>

<h2><a name="dfs_cbsd_hooks">Хуки <strong>CBSD</strong> для работы с DFS</a></h2>

<p>Если вы выходите за рамки кейса, когда все данные окружений расположены на локальной файловой системе ZFS/UFS, перед вами встает вопрос предвартительного монтирования
ресурса, содержащего данные окружения. Для этого, в <strong>CBSD</strong> используются параметры <strong>mnt_start</strong> и <strong>mnt_stop</strong>, в которых вы 
указываете кастомный скрипты, работающие при старте и при останове окружения. Это может быть любой executable скрипт, для успешной работы с <strong>CBSD</strong> которого
нужно соблюсти несколько правил:</p>

	<ul>
		<li>Ваш скрипт должен быть устойчив к вторичному монтированию. Например, вы стартовали окружение, затем остановили и запустили вновь. Ваш скрипт не должен
		монтировать поверх предыдущего монтирования еще раз - эта проверка и это поведение на совести вашего скрипта - проверяйте факт монтирования</li>
		<li>Ваш скрипт должен завершиться с кодом 0 при успехе или ненулевым кодом при фатальных проблемах</li>
		<li>Время работы вашего хука неограничено - избегайте ситуации, когда ваш скрипт может висеть вечно</li>
		<li><strong>CBSD</strong> запускает скрипт с определенными аргументами для передачи некоторой полезной информации. Ваш скрипт должен обрабатывать опции через getopt чтобы принять их. Это следующие ключи:
		<table class="images">
			<tr><td><strong>-d</strong></td><td>data - путь к каталогу данных окружения;</td></tr>
			<tr><td><strong>-f</strong></td><td>fstab - путь к каталогу fstab (актуально в основном для jail);</td></tr>
			<tr><td><strong>-j</strong></td><td>jname - непосредственно имя вашего окружения;</td></tr>
			<tr><td><strong>-r</strong></td><td>rcconf - путь к каталогу rcconf;</td></tr>
			<tr><td><strong>-s</strong></td><td>sysdata - путь к каталогу sysdata;</td></tr>
		</table>
		</li>
	</ul>

	<p>Как видите, использование этих параметров с возможностью создавать кастомные сценарии для подключения внешних хранилищ, дает вам возможность использовать сценарии, о которых не слышал ни один белый человек, например:
	iSCSI, Infiniband, GELI, HASTD и тд.</p>

	<p>В качестве рабочего примера посмотрите на скрипт для работы с NFSv4 в следующем параграфе.</p>

	<p>Кроме этого, вам может быть полезно знать о возможности кастомных операций по клонированию - например, если вы контроллируете ваш внешний сторедж и он может выполнять операции по копированю данных на своей стороне,
	вы можете избежать высокой нагрузки на сеть при обычном копировании информации, а сделать моментальный клон средствами внешнего накопителя.
	Подробнее об этом сценарии смотрите <a href="/<!--#echo var="lang" -->/<!--#echo var="version" -->/wf_jclone_ssi.html#clone-local.d%20hook:%20local/custom%20data%20clone">здесь</a> и <a target="_blank" href="https://github.com/cbsd/cbsd/issues/373">здесь</a>.</p>

<h2><a name="dfs_nfs">CBSD и NFSv4</a></h2>

<p>Использование <strong>CBSD</strong> с NFS ( вариант, когда в качестве NFS выступает не выделенный NAS, а одна из трех <strong>CBSD</strong> нод )</p>

<p>Через различные механизмы отказоустойчивости, такие как  <a href="http://man.freebsd.org/carp/4" target="_blank">carp(4)</a>, <strong>pacemaker/corosync</strong>, 
<strong>keepalive</strong>, <strong>sentinel/consul</strong>, вы можете создать полностью автоматический фейловер, когда при выходе NFS-сервера,
в качестве хранилища выбирается любая другая нода, а остальные переконфигурируются на нее. Однако подобные настройки выходят за рамки данной статьи, призванной дать поверхносные данные о DFS.</p>

<p>Итак, на первом из трех сервере, выбранным нами в качестве NFS-сервера, настроем файл <em>>/etc/exports</em>, перечисляя IP или подсети NFS-слиентов.
Мы предполагаем, что сервера полностью под нашим контролем и находятся под полным доверием, поскольку будем давать экспортировать все каталоги.</p>

<p>Например, наши три <strong>CBSD</strong> ноды имеют адреса: <strong>192.168.10.201 192.168.10.202 192.168.10.203</strong> и рабочий каталог <strong>workdir</strong> везде проинициализирован в <em>/usr/jails</em>.</p>
<p>Добавим в <em>/etc/exports</em> соответствующую NFSv4 строчку:</p>
<pre class="cli">
V4: / 192.168.10.201 192.168.10.202 192.168.10.203
</pre>

<p>Если ваши сервера проинсталлированы на ZFS файловой системе, не забудьте включить sharenfs опцию на необходимых или на корневом датасете на NFS-сервере. Например, если корневая система ZFS это zroot/ROOT/default, то экспорт NFS включается через следующую команду:</p>
<pre class="brush:bash;ruler:rule;">
% zfs set sharenfs=on zroot/ROOT/default
</pre>

<p>В <em>/etc/rc.conf</em> добавим необходимые для запуска NFS-сервера службы, выполнив команды:</p>

<pre class="brush:bash;ruler:rule;">
sysrc -q nfs_client_enable="YES"
sysrc -q nfs_server_enable="YES"
sysrc -q nfsv4_server_enable="YES"
sysrc -q nfscbd_enable="YES"
sysrc -q nfsuserd_enable="YES"
sysrc -q rpcbind_enable="YES"
sysrc -q mountd_enable="YES"
sysrc -q nfsuserd_enable="YES"
sysrc -q rpc_lockd_enable="YES"
</pre>

<p>Если вы планируете делать фейловер и таким образом, NFS-сервером может стать любой элемент кластера, поэтому продублируем эти параметры на все остальные <strong>CBSD</strong> ноды, тем более, что часть из них необходима для NFS клиента.
После перезагрузки серверов или служб, NFS готова к работе.</p>

<p>Конфигурирование клиентов. В нашем случае, NFS-сервер имеет IP адрес 192.168.10.201, соотв. замените этот адрес на тот, который соответствует вашему серверу.
Подмонтировать в ручном режиме каталоги можно через команды:</p>

<pre>
% mount_nfs -o vers=4 192.168.10.201:/usr/jails/jails-data /usr/jails/jails-data
% mount_nfs -o vers=4 192.168.10.201:/usr/jails/jails-system /usr/jails/jails-system
% mount_nfs -o vers=4 192.168.10.201:/usr/jails/jails-rcconf /usr/jails/jails-rcconf
</pre>

<p>Вы можете использовать файл <em>/etc/fstab</em> с опцией 'late' для монтирования каталогов при старте ноды, либо использовать automount  ( <a href="http://man.freebsd.org/autofs/5" target="_blank">autofs(5)</a> )</p>
<p>Теперь вы можете создавать ваши контейнера на любой из нод и через миграцию или последовательность команд:</p>

<pre>
node1 % cbsd junregister jname='jail*'     // на ноде, где зарегистрированы jail
node2 % cbsd jregister jname='jail*'       // на другой ноде
</pre>

<p>И мигрировать ваши окружения, распределяя и маcштабируя нагрузку на ваш кластер более ровно.</p>


<h2><a name="dfs_glusterfs">CBSD и GlusterFS</a></h2>

<br>
<p>WIP. Короткий HowTo доступен здесь: <a href="/<!--#echo var="lang" -->/articles/cbsd_jail_glusterfs.html">CBSD и GlusterFS</a></p>
<br>

<h2><a name="dfs_ceph">CBSD и CEPH</a></h2>

<br>
<p>WIP/<p>
<br>

</div>
<!--# include file="/ru/_end.html" -->
